{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JustAlex5/deep_learning/blob/main/ex10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xbxw0bG3TFhx"
      },
      "source": [
        "# Deep Learning: Ex.10 - RNN\n",
        "\n",
        "Submitted by: [... **your name and ID** ...]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "WsWcF11bTFh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c73bc330-d5cf-4e02-d1aa-b7d8613c3935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM # <--- recurrent layers\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from seaborn import heatmap\n",
        "import re\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VU517batTiks"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R67-cySTj92",
        "outputId": "7f5ecef7-285a-4205-fd0e-973d1c3ee015"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls '/content/drive/MyDrive/Ex10'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIgoq-S8Tu5f",
        "outputId": "3f950b39-24d9-4570-cb73-28192ff716f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "war_and_peace.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/drive/MyDrive/Ex10/war_and_peace.txt'"
      ],
      "metadata": {
        "id": "LN6aBGzxT9xh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3blM1K8TFh1"
      },
      "source": [
        "***\n",
        "### 1. Preprocess the text corpus\n",
        "\n",
        "(if you are using google colab, remember to upload the corpus file first..)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HIeehSdTFh1",
        "outputId": "ce795ad2-1495-4a80-e110-a8b188862de2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(text) =  3021421\n",
            "well prince so genoa and lucca are now just family estates of thebuonapartes but i warn you if you dont tell me that this means warif you still try to defend the infamies and horrors perpetrated by thatantichristi really believe he is antichristi will have nothing moreto do with you and you are no longer my friend no longer my faithfulslave as you call yourself but how do you do i see i have frigh\n"
          ]
        }
      ],
      "source": [
        "f = open(path,'r') # open the corpus file\n",
        "\n",
        "text = f.read().lower()  # read file and convert to lower-case letters\n",
        "# text= text.replace('\\n', ' ')\n",
        "text = re.sub(r'[^a-zA-Z0-9 ]',r'',text)\n",
        "\n",
        "print('len(text) = ',len(text))\n",
        "\n",
        "\n",
        "print(text[:400]) # print the first 400 characters.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT6dzK3KTFh2"
      },
      "source": [
        "- generate training sequences of `T=20` characters, by sampling the text corpus with a stride of 5 characters (i.e., each sequences starts 5 chars after the begining of the last sequences).\n",
        "\n",
        "- generate a matching list, holding the `next_char` for each of your sequences.\n",
        "\n",
        "- how many sequences did you extract in total? `N = ?`\n",
        "\n",
        "- convert the sequences into a 1-hot representation, suitable for our model trainig:\n",
        "\n",
        "`X.shape = (N, T, len(chars))`\n",
        "\n",
        "`Y.shape = (N, len(chars))`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "text_size, vocab_size = len(text), len(chars)\n",
        "print('There are %d total characters and %d unique characters in your data.' % (text_size, vocab_size))\n",
        "print('chars = ',chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7yspK6i1IE9",
        "outputId": "6509f572-1d5c-4cea-e2b2-85f62cfc84c3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 3083435 total characters and 37 unique characters in your data.\n",
            "chars =  [' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
        "\n",
        "ix_to_char"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAbl5vvq1g-Q",
        "outputId": "979717a6-1f7f-48bd-e8d0-512f4ba9a072"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: ' ',\n",
              " 1: '0',\n",
              " 2: '1',\n",
              " 3: '2',\n",
              " 4: '3',\n",
              " 5: '4',\n",
              " 6: '5',\n",
              " 7: '6',\n",
              " 8: '7',\n",
              " 9: '8',\n",
              " 10: '9',\n",
              " 11: 'a',\n",
              " 12: 'b',\n",
              " 13: 'c',\n",
              " 14: 'd',\n",
              " 15: 'e',\n",
              " 16: 'f',\n",
              " 17: 'g',\n",
              " 18: 'h',\n",
              " 19: 'i',\n",
              " 20: 'j',\n",
              " 21: 'k',\n",
              " 22: 'l',\n",
              " 23: 'm',\n",
              " 24: 'n',\n",
              " 25: 'o',\n",
              " 26: 'p',\n",
              " 27: 'q',\n",
              " 28: 'r',\n",
              " 29: 's',\n",
              " 30: 't',\n",
              " 31: 'u',\n",
              " 32: 'v',\n",
              " 33: 'w',\n",
              " 34: 'x',\n",
              " 35: 'y',\n",
              " 36: 'z'}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "zR-7S1GQTFh2"
      },
      "outputs": [],
      "source": [
        "    ###########################\n",
        "    ###  your code here...  ###\n",
        "    ###########################\n",
        "\n",
        "T = 20  # extract training sequences of length T\n",
        "stride = 5\n",
        "\n",
        "sequences = []  # This holds our extracted sequences\n",
        "next_chars = []  # This holds the targets (the follow-up character)\n",
        "\n",
        "for i in range(0, len(text) - T, stride):\n",
        "  sequences.append(text[i: i + T])\n",
        "  next_chars.append(text[i + T])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o74b8dBbzJJH",
        "outputId": "eec949dd-bd6e-4ad3-923c-59cf926df0bf"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "616683"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    print(sequences[i], '->', next_chars[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTWHc2iTzKBF",
        "outputId": "6e0f9e66-462f-497e-bbf3-f6e36c8475ac"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "well prince so genoa ->  \n",
            "prince so genoa and  -> l\n",
            "e so genoa and lucca ->  \n",
            "genoa and lucca are  -> n\n",
            " and lucca are now j -> u\n",
            "lucca are now just f -> a\n",
            " are now just family ->  \n",
            "now just family esta -> t\n",
            "ust family estates o -> f\n",
            "amily estates of the -> b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TZYrJBPnHsC6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(sequences), T, len(chars)), dtype='bool')\n",
        "Y = np.zeros((len(sequences), len(chars)), dtype='bool')\n",
        "\n",
        "for i, seq in enumerate(sequences):\n",
        "    for t, char in enumerate(seq):\n",
        "        X[i, t, char_to_ix[char]] = 1\n",
        "    Y[i, char_to_ix[next_chars[i]]] = 1\n",
        "    \n",
        "print('X.shape = (#examples, T, input-dim) =', X.shape)\n",
        "print('Y.shape = (#examples, output-dim) =', Y.shape)"
      ],
      "metadata": {
        "id": "4FhvWrHGzayB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e101cd7a-638f-42ce-9df8-d4ce651218ee"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape = (#examples, T, input-dim) = (604281, 20, 37)\n",
            "Y.shape = (#examples, output-dim) = (604281, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwP0kVXlTFh2"
      },
      "source": [
        "*** **bold text**\n",
        "### 2. LTSM Model\n",
        "\n",
        "- Build an `LTSM` model with 128 (hidden)-units that accepts the input sequences. Add a `Dense` layer on top of it, with `len(chars)` softmax units.\n",
        "\n",
        "- Train the model for only 1 epoch (use: `RMSprop` and batch size of 128).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "vC_81a9KTFh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "351f4ed7-f880-4f8b-f854-2aa78c8a9c70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_1 (LSTM)               (None, 128)               84992     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 37)                4773      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 89,765\n",
            "Trainable params: 89,765\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "    ###########################\n",
        "    ###  your code here...  ###\n",
        "    ###########################\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(T, len(chars))))  # (12,27)\n",
        "model.add(LSTM (128)) # 32 internal state units\n",
        "model.add(Dense(len(chars), activation=\"softmax\"))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "history = model.fit(X, Y, epochs=1, batch_size=128)"
      ],
      "metadata": {
        "id": "WMS6hVMrNT8z",
        "outputId": "a27a59ef-2ea6-4cb0-b8be-509812b9a609",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4818/4818 [==============================] - 29s 6ms/step - loss: 2.0186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9mPsVgmTFh4"
      },
      "source": [
        "### 3. Model predictions\n",
        "\n",
        "\n",
        "- use the senternce `the meaning of life ` as an input to the model (convert it to 1-hot first..),\n",
        "\n",
        "- plot the model's output as a probability distribution over the list of chars.\n",
        "\n",
        "- sample a single char from that distribution, and add it to the generated sentence.\n",
        "\n",
        "- update the 1-hot buffer, and continue the process for 99 more letters (using a loop).\n",
        "\n",
        "- print the resulting sentence."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence='the meaning of life'\n",
        "one_hot_sentence = np.zeros((len(sentence), T, len(chars)), dtype='bool')"
      ],
      "metadata": {
        "id": "rSKCR1tOQT0c"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "fU1Lfp9NTFh4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "d9f8ca1c-992c-4ce9-fa48-7438f0a7ba99"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "    ###########################\n",
        "    ###  your code here...  ###\n",
        "    ###########################\n",
        "yhat=model.predict(one_hot_sentence)\n",
        "plt.figure(figsize=(14,4))\n",
        "plt.bar(range(len(chars)), yhat[0])\n",
        "plt.xticks(range(len(chars)), labels=chars)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_buffer = one_hot_sentence[0]\n",
        "generated_text = sentence\n",
        "\n",
        "yy = []\n",
        "\n",
        "for i in range(100):\n",
        "    yhat = model.predict(input_buffer[None,:])\n",
        "\n",
        "    # sample the next character:\n",
        "    # ix = np.argmax(yhat)\n",
        "    ix = np.random.choice(range(len(chars)), p=yhat[0])\n",
        "\n",
        "    ch = ix_to_char[ix]\n",
        "    generated_text += ch\n",
        "\n",
        "    # update the input buffer:\n",
        "    input_buffer = np.r_[input_buffer[1:,:], np.zeros((1,len(chars)))]\n",
        "    input_buffer[-1,ix] = 1\n",
        "\n",
        "    yy.append(yhat)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "MqXeKYM6RCxK",
        "outputId": "e00721ab-b37a-48a1-98b4-2cc04a205bfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the meaning of lifety he sauk of michuming so stokntity this shighted to whole he meger torzerthing the nontesscas and \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNqz3-xNTFh4"
      },
      "source": [
        "***\n",
        "### 3. Fit your model\n",
        "\n",
        "- Fit your model a bit more (try 10-20 epochs), and regenerate a new `N=100` sentence sample. Does it get any better?\n",
        "\n",
        "- If you wish, you can try to train the model further, or you can try using a different corpus (dataset) for the training (you can even try a text in hebrew). Be creative ;)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "m2IcyDJwTFh5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6318dd81-953a-4e3f-d5e9-52aebc0cc7a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4818/4818 [==============================] - 30s 6ms/step - loss: 1.6424\n",
            "Epoch 2/20\n",
            "4818/4818 [==============================] - 26s 5ms/step - loss: 1.5137\n",
            "Epoch 3/20\n",
            "4818/4818 [==============================] - 26s 5ms/step - loss: 1.4423\n",
            "Epoch 4/20\n",
            "4818/4818 [==============================] - 26s 5ms/step - loss: 1.3957\n",
            "Epoch 5/20\n",
            "4818/4818 [==============================] - 26s 5ms/step - loss: 1.3618\n",
            "Epoch 6/20\n",
            "4818/4818 [==============================] - 26s 5ms/step - loss: 1.3362\n",
            "Epoch 7/20\n",
            "4818/4818 [==============================] - 26s 5ms/step - loss: 1.3156\n",
            "Epoch 8/20\n",
            "4818/4818 [==============================] - 26s 5ms/step - loss: 1.2991\n",
            "Epoch 9/20\n",
            "4818/4818 [==============================] - 26s 5ms/step - loss: 1.2850\n",
            "Epoch 10/20\n",
            "4818/4818 [==============================] - 26s 5ms/step - loss: 1.2730\n",
            "Epoch 11/20\n",
            "4818/4818 [==============================] - 25s 5ms/step - loss: 1.2626\n",
            "Epoch 12/20\n",
            "4818/4818 [==============================] - 26s 5ms/step - loss: 1.2531\n",
            "Epoch 13/20\n",
            "4818/4818 [==============================] - 26s 5ms/step - loss: 1.2445\n",
            "Epoch 14/20\n",
            "4818/4818 [==============================] - 26s 5ms/step - loss: 1.2374\n",
            "Epoch 15/20\n",
            "4818/4818 [==============================] - 26s 5ms/step - loss: 1.2309\n",
            "Epoch 16/20\n",
            "4818/4818 [==============================] - 26s 5ms/step - loss: 1.2243\n",
            "Epoch 17/20\n",
            "4818/4818 [==============================] - 26s 5ms/step - loss: 1.2190\n",
            "Epoch 18/20\n",
            "4818/4818 [==============================] - 26s 5ms/step - loss: 1.2141\n",
            "Epoch 19/20\n",
            "4818/4818 [==============================] - 26s 5ms/step - loss: 1.2094\n",
            "Epoch 20/20\n",
            "4818/4818 [==============================] - 27s 6ms/step - loss: 1.2056\n"
          ]
        }
      ],
      "source": [
        "    ###########################\n",
        "    ###  your code here...  ###\n",
        "    ###########################\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "history_20 = model.fit(X, Y, epochs=20, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_buffer = one_hot_sentence[0]\n",
        "generated_text = sentence\n",
        "\n",
        "yy = []\n",
        "\n",
        "for i in range(200):\n",
        "    yhat = model.predict(input_buffer[None,:])\n",
        "\n",
        "    # sample the next character:\n",
        "    # ix = np.argmax(yhat)\n",
        "    ix = np.random.choice(range(len(chars)), p=yhat[0])\n",
        "\n",
        "    ch = ix_to_char[ix]\n",
        "    generated_text += ch\n",
        "\n",
        "    # update the input buffer:\n",
        "    input_buffer = np.r_[input_buffer[1:,:], np.zeros((1,len(chars)))]\n",
        "    input_buffer[-1,ix] = 1\n",
        "\n",
        "    yy.append(yhat)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "GjsG1rXwWxJM",
        "outputId": "d49177cb-440e-4186-a86a-77db2cca8712",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the meaning of lifeqjjjjent harms to bean to be othelf its princessiativn that joy and districted him hows but always sent his eyes in roility of dinners and as if now still with entering to allowed and noticed near the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "   !tar -xzvf \"/content/drive/MyDrive/Ex10/to_realdonaldtrump_20171201_ids.txt.tar.gz\" -C \"/content/drive/MyDrive/Ex10/\""
      ],
      "metadata": {
        "id": "WXAKykFscaPZ",
        "outputId": "93caa63e-740a-4bf1-ea3d-c3575060d946",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "to_realdonaldtrump_20171201_ids.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls /content/drive/MyDrive/Ex10"
      ],
      "metadata": {
        "id": "j_bx8EXVdo2x",
        "outputId": "903dc5c1-31f7-48db-fe1b-b1bed1d76179",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "to_realdonaldtrump_20171201_ids.txt         war_and_peace.txt\n",
            "to_realdonaldtrump_20171201_ids.txt.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path2= '/content/drive/MyDrive/Ex10/output.txt'"
      ],
      "metadata": {
        "id": "8Ntzbwcrc9ja"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(path2,'r') # open the corpus file\n",
        "\n",
        "text = f.read().lower()  # read file and convert to lower-case letters\n",
        "# text= text.replace('\\n', ' ')\n",
        "# text = re.sub(r'[^a-zA-Z0-9 ]',r'',text)\n",
        "\n",
        "print('len(text) = ',len(text))\n",
        "\n",
        "\n",
        "print(text[:400]) # print the first 400 characters.."
      ],
      "metadata": {
        "id": "txINnBn3dVjI",
        "outputId": "a0d4ac0a-8dd4-450b-9f72-b5c0af17b031",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(text) =  754765\n",
            "the question in this election: who can put the plans into action that will make your life better? https://t.co/xreey9oicg\n",
            "last night, donald trump said not paying taxes was \"smart.\" you know what i call it? unpatriotic. https://t.co/t0xmbfj7zf\n",
            "couldn't be more proud of @hillaryclinton. her vision and command during last night's debate showed that she's ready to be our next @potus.\n",
            "if we stand toge\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "text_size, vocab_size = len(text), len(chars)\n",
        "print('There are %d total characters and %d unique characters in your data.' % (text_size, vocab_size))\n",
        "print('chars = ',chars)"
      ],
      "metadata": {
        "id": "UqEirv-uh1Ow",
        "outputId": "08d54752-0790-410b-ef53-f251d2811c3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 754765 total characters and 125 unique characters in your data.\n",
            "chars =  ['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '@', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '~', '\\xa0', '¡', '®', '¿', 'á', 'é', 'í', 'ñ', 'ó', 'ú', 'ĺ', '̶', '\\u200a', '\\u200b', '–', '—', '‘', '’', '“', '”', '•', '…', '⁰', '→', '✅', '✓', '✔', '❌', '❤', '⬇', '️', '🇸', '🇺', '🌈', '🍕', '🎓', '🎤', '🎧', '🏡', '🏻', '🏼', '🏽', '🏾', '🏿', '🐣', '👀', '👇', '👈', '👉', '👍', '👎', '👏', '👸', '👿', '💁', '💨', '💪', '📚', '🗽', '🚂', '🤔', '🤖']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
        "\n",
        "ix_to_char"
      ],
      "metadata": {
        "id": "AGNyLcY6h7tL",
        "outputId": "e0453fb1-750f-431d-ef76-dd35b0457d73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '\\n',\n",
              " 1: ' ',\n",
              " 2: '!',\n",
              " 3: '\"',\n",
              " 4: '#',\n",
              " 5: '$',\n",
              " 6: '%',\n",
              " 7: '&',\n",
              " 8: \"'\",\n",
              " 9: '(',\n",
              " 10: ')',\n",
              " 11: '*',\n",
              " 12: '+',\n",
              " 13: ',',\n",
              " 14: '-',\n",
              " 15: '.',\n",
              " 16: '/',\n",
              " 17: '0',\n",
              " 18: '1',\n",
              " 19: '2',\n",
              " 20: '3',\n",
              " 21: '4',\n",
              " 22: '5',\n",
              " 23: '6',\n",
              " 24: '7',\n",
              " 25: '8',\n",
              " 26: '9',\n",
              " 27: ':',\n",
              " 28: ';',\n",
              " 29: '=',\n",
              " 30: '?',\n",
              " 31: '@',\n",
              " 32: '[',\n",
              " 33: ']',\n",
              " 34: '_',\n",
              " 35: 'a',\n",
              " 36: 'b',\n",
              " 37: 'c',\n",
              " 38: 'd',\n",
              " 39: 'e',\n",
              " 40: 'f',\n",
              " 41: 'g',\n",
              " 42: 'h',\n",
              " 43: 'i',\n",
              " 44: 'j',\n",
              " 45: 'k',\n",
              " 46: 'l',\n",
              " 47: 'm',\n",
              " 48: 'n',\n",
              " 49: 'o',\n",
              " 50: 'p',\n",
              " 51: 'q',\n",
              " 52: 'r',\n",
              " 53: 's',\n",
              " 54: 't',\n",
              " 55: 'u',\n",
              " 56: 'v',\n",
              " 57: 'w',\n",
              " 58: 'x',\n",
              " 59: 'y',\n",
              " 60: 'z',\n",
              " 61: '|',\n",
              " 62: '~',\n",
              " 63: '\\xa0',\n",
              " 64: '¡',\n",
              " 65: '®',\n",
              " 66: '¿',\n",
              " 67: 'á',\n",
              " 68: 'é',\n",
              " 69: 'í',\n",
              " 70: 'ñ',\n",
              " 71: 'ó',\n",
              " 72: 'ú',\n",
              " 73: 'ĺ',\n",
              " 74: '̶',\n",
              " 75: '\\u200a',\n",
              " 76: '\\u200b',\n",
              " 77: '–',\n",
              " 78: '—',\n",
              " 79: '‘',\n",
              " 80: '’',\n",
              " 81: '“',\n",
              " 82: '”',\n",
              " 83: '•',\n",
              " 84: '…',\n",
              " 85: '⁰',\n",
              " 86: '→',\n",
              " 87: '✅',\n",
              " 88: '✓',\n",
              " 89: '✔',\n",
              " 90: '❌',\n",
              " 91: '❤',\n",
              " 92: '⬇',\n",
              " 93: '️',\n",
              " 94: '🇸',\n",
              " 95: '🇺',\n",
              " 96: '🌈',\n",
              " 97: '🍕',\n",
              " 98: '🎓',\n",
              " 99: '🎤',\n",
              " 100: '🎧',\n",
              " 101: '🏡',\n",
              " 102: '🏻',\n",
              " 103: '🏼',\n",
              " 104: '🏽',\n",
              " 105: '🏾',\n",
              " 106: '🏿',\n",
              " 107: '🐣',\n",
              " 108: '👀',\n",
              " 109: '👇',\n",
              " 110: '👈',\n",
              " 111: '👉',\n",
              " 112: '👍',\n",
              " 113: '👎',\n",
              " 114: '👏',\n",
              " 115: '👸',\n",
              " 116: '👿',\n",
              " 117: '💁',\n",
              " 118: '💨',\n",
              " 119: '💪',\n",
              " 120: '📚',\n",
              " 121: '🗽',\n",
              " 122: '🚂',\n",
              " 123: '🤔',\n",
              " 124: '🤖'}"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "T = 20  # extract training sequences of length T\n",
        "stride = 5\n",
        "\n",
        "sequences = []  # This holds our extracted sequences\n",
        "next_chars = []  # This holds the targets (the follow-up character)\n",
        "\n",
        "for i in range(0, len(text) - T, stride):\n",
        "  sequences.append(text[i: i + T])\n",
        "  next_chars.append(text[i + T])"
      ],
      "metadata": {
        "id": "e4HYFnR6iJHM"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(sequences), T, len(chars)), dtype='bool')\n",
        "Y = np.zeros((len(sequences), len(chars)), dtype='bool')\n",
        "\n",
        "for i, seq in enumerate(sequences):\n",
        "    for t, char in enumerate(seq):\n",
        "        X[i, t, char_to_ix[char]] = 1\n",
        "    Y[i, char_to_ix[next_chars[i]]] = 1\n",
        "    \n",
        "print('X.shape = (#examples, T, input-dim) =', X.shape)\n",
        "print('Y.shape = (#examples, output-dim) =', Y.shape)"
      ],
      "metadata": {
        "id": "0J96NHY0iMZa",
        "outputId": "46ae970a-06f3-47b1-fb59-ffa76b6d6294",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape = (#examples, T, input-dim) = (150949, 20, 125)\n",
            "Y.shape = (#examples, output-dim) = (150949, 125)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(T, len(chars))))  # (12,27)\n",
        "model.add(LSTM (256)) # 32 internal state units\n",
        "model.add(Dense(len(chars), activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "rB3n_cW7iRe8",
        "outputId": "53e1b698-be93-4c7d-cbdf-d93b44619e12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 256)               391168    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 125)               32125     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 423,293\n",
            "Trainable params: 423,293\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0Ae9U-ZziZVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "trump = model.fit(X, Y, epochs=1, batch_size=128)"
      ],
      "metadata": {
        "id": "INZ2u9YviVY5",
        "outputId": "5db241af-c4dc-4e07-a8bd-71e7dfc87a2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1180/1180 [==============================] - 9s 6ms/step - loss: 2.6997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence='the meaning of life'\n",
        "one_hot_sentence = np.zeros((len(sentence), T, len(chars)), dtype='bool')"
      ],
      "metadata": {
        "id": "xD6nIT3-ieDF"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_buffer = one_hot_sentence[0]\n",
        "generated_text = sentence\n",
        "\n",
        "yy = []\n",
        "\n",
        "for i in range(100):\n",
        "    yhat = model.predict(input_buffer[None,:])\n",
        "\n",
        "    # sample the next character:\n",
        "    # ix = np.argmax(yhat)\n",
        "    ix = np.random.choice(range(len(chars)), p=yhat[0])\n",
        "\n",
        "    ch = ix_to_char[ix]\n",
        "    generated_text += ch\n",
        "\n",
        "    # update the input buffer:\n",
        "    input_buffer = np.r_[input_buffer[1:,:], np.zeros((1,len(chars)))]\n",
        "    input_buffer[-1,ix] = 1\n",
        "\n",
        "    yy.append(yhat)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "C3s7L-CLihR1",
        "outputId": "1c10fc02-104a-4276-ba23-fcaa1e7b8957",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the meaning of lifej to y certeadcnntud. thillfot ftou vea!gton't hot #hith ttis doolindt\"\n",
            "ats meslians nom geomard tpr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "trump = model.fit(X, Y, epochs=50, batch_size=64)"
      ],
      "metadata": {
        "id": "Vob8wEG3iqDr",
        "outputId": "b57bb072-d6e3-428a-de76-8498032e07da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "2359/2359 [==============================] - 14s 5ms/step - loss: 2.1695\n",
            "Epoch 2/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 1.9302\n",
            "Epoch 3/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 1.7830\n",
            "Epoch 4/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 1.6741\n",
            "Epoch 5/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 1.5841\n",
            "Epoch 6/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 1.5077\n",
            "Epoch 7/50\n",
            "2359/2359 [==============================] - 13s 5ms/step - loss: 1.4386\n",
            "Epoch 8/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 1.3726\n",
            "Epoch 9/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 1.3123\n",
            "Epoch 10/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 1.2524\n",
            "Epoch 11/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 1.1961\n",
            "Epoch 12/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 1.1409\n",
            "Epoch 13/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 1.0914\n",
            "Epoch 14/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 1.0439\n",
            "Epoch 15/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 1.0001\n",
            "Epoch 16/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.9605\n",
            "Epoch 17/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.9238\n",
            "Epoch 18/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.8885\n",
            "Epoch 19/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.8591\n",
            "Epoch 20/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.8302\n",
            "Epoch 21/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.8051\n",
            "Epoch 22/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.7833\n",
            "Epoch 23/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.7599\n",
            "Epoch 24/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.7442\n",
            "Epoch 25/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.7281\n",
            "Epoch 26/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.7125\n",
            "Epoch 27/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.6986\n",
            "Epoch 28/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.6857\n",
            "Epoch 29/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.6740\n",
            "Epoch 30/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.6613\n",
            "Epoch 31/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.6505\n",
            "Epoch 32/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.6434\n",
            "Epoch 33/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.6340\n",
            "Epoch 34/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.6282\n",
            "Epoch 35/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.6201\n",
            "Epoch 36/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.6121\n",
            "Epoch 37/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.6071\n",
            "Epoch 38/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.5988\n",
            "Epoch 39/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.5942\n",
            "Epoch 40/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.5866\n",
            "Epoch 41/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.5815\n",
            "Epoch 42/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.5795\n",
            "Epoch 43/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.5723\n",
            "Epoch 44/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.5693\n",
            "Epoch 45/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.5644\n",
            "Epoch 46/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.5590\n",
            "Epoch 47/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.5563\n",
            "Epoch 48/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.5511\n",
            "Epoch 49/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.5462\n",
            "Epoch 50/50\n",
            "2359/2359 [==============================] - 12s 5ms/step - loss: 0.5418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_buffer = one_hot_sentence[0]\n",
        "generated_text = sentence\n",
        "\n",
        "yy = []\n",
        "\n",
        "for i in range(200):\n",
        "    yhat = model.predict(input_buffer[None,:])\n",
        "\n",
        "    # sample the next character:\n",
        "    # ix = np.argmax(yhat)\n",
        "    ix = np.random.choice(range(len(chars)), p=yhat[0])\n",
        "\n",
        "    ch = ix_to_char[ix]\n",
        "    generated_text += ch\n",
        "\n",
        "    # update the input buffer:\n",
        "    input_buffer = np.r_[input_buffer[1:,:], np.zeros((1,len(chars)))]\n",
        "    input_buffer[-1,ix] = 1\n",
        "\n",
        "    yy.append(yhat)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "knZlQF91jrZT",
        "outputId": "0538f397-a3c9-4c1f-b2b4-34d851e4841a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the meaning of life-k's werk watch time to day  he winterele. https://t.co/bf6ngod8bt\n",
            "the best way that sad your most bankrating he xill him he ..don't sey country be very work for won for u...\n",
            "\n",
            "we will make america gre\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjSwVGzbTFh5"
      },
      "source": [
        "***\n",
        "## Good Luck!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "ex10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}