{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG_RNN.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMJZKBw5ux9XaYsO+L7qMbl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JustAlex5/deep_learning/blob/main/VGG_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9Uc76hSzSIW",
        "outputId": "6c056e00-2b70-4ca3-b246-8d629814fdef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models,Input\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D,Dropout\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM ,RepeatVector,Reshape# <--- recurrent layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import re\n",
        "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator, array_to_img\n",
        "from PIL import Image\n",
        "import datetime\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.layers import Input, Dense, Dropout, LSTM, Embedding\n",
        "from keras.layers.merge import add\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "print(tf.__version__)\n",
        "PATH=\"/content/drive/MyDrive/Fina_Prj/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip\n",
        "\n",
        "!wget -q https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip\n",
        "\n",
        "!unzip -qq Flickr8k_Dataset.zip\n",
        "\n",
        "!unzip -qq Flickr8k_text.zip"
      ],
      "metadata": {
        "id": "8yuH4DPYzV7k"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtbjvyWHzbF3",
        "outputId": "57a951d3-52da-4b25-c8b6-ebab745a217d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path=\"/content/drive/MyDrive/Fina_Prj/Flicker8k_Dataset/\"\n",
        "txt_path=\"/content/drive/MyDrive/Fina_Prj/Flickr8k_text/\""
      ],
      "metadata": {
        "id": "3M4fXS40zefd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict={}\n",
        "data = open(txt_path+'Flickr8k.lemma.token.txt', 'r')\n",
        "\n",
        "lines= data.readlines()\n",
        "max_seq=0\n",
        "# creat dictionary of images (train and test)\n",
        "# each img contain all the descriptions \n",
        "# convert to lower case and delete new line char\n",
        "for line in lines:\n",
        "    a,b=line.split(\"\\t\",1)\n",
        "    a=a.split(\"#\")\n",
        "    b=re.sub(r'[^a-zA-Z0-9 ]',r'',b.lower())\n",
        "    b=b.split(\" \")\n",
        "    b.insert(0,'<start>')\n",
        "    b.insert(len(b)-1,'<stop>')\n",
        "    b=b[:-1]\n",
        "    b=\" \".join(b)\n",
        "    if a[0]  in dict.keys():       \n",
        "        dict[a[0]].append(b)\n",
        "    else: \n",
        "        dict.update({a[0]:[b]})\n",
        "\n",
        "train_dict={}\n",
        "\n",
        "# open the train images list\n",
        "data_train = open(txt_path+'Flickr_8k.trainImages.txt', 'r')\n",
        "lines= data_train.readlines()\n",
        "# copy the descriptions of only train images to new dictionary\n",
        "for line in lines:\n",
        "    line=line.replace('\\n','')\n",
        "    if line in dict.keys():\n",
        "        train_dict[line]=dict[line]\n",
        "\n",
        "words={}\n",
        "new_word={}\n",
        "train_dict_new={}\n",
        "# count all word in the end there dictionary with all words in the train and times that repeats \n",
        "for key_item in train_dict:\n",
        "    value_item= train_dict[key_item]\n",
        "    tmp_item=\" \".join(value_item)\n",
        "    tmp_item=tmp_item.split(\" \")\n",
        "    for item in tmp_item:\n",
        "        if len(item) ==1:\n",
        "            continue\n",
        "        if item in words.keys():\n",
        "            words.update({item:words.get(item)+1})\n",
        "        else:\n",
        "            words.update({item:1})\n",
        "for key_item in words:\n",
        "    value_item= words[key_item]\n",
        "    if value_item >5:\n",
        "        # copy all words to new dictionary \n",
        "        new_word[key_item]=words[key_item]\n",
        "\n",
        "# delete all words that apears less than 5 times \n",
        "for key_item in train_dict:\n",
        "    value_item=train_dict[key_item]\n",
        "    tmp_string=\",\".join(value_item)\n",
        "    tmp_string=tmp_string.split(\",\")\n",
        "    res=[]\n",
        "    for item in tmp_string:\n",
        "        a=[]\n",
        "        items=item.split(\" \")\n",
        "        if len(items)>max_seq:\n",
        "            max_seq=len(items)\n",
        "        for item in items:\n",
        "            if item in new_word.keys():\n",
        "                a.append(item)\n",
        "        res.append(a)\n",
        "        train_dict_new.update({key_item:res})   \n",
        "final_dict={}\n",
        "idx_word={}\n",
        "idx_word.update({0:\" \"})\n",
        "\n",
        "for x,y in enumerate(new_word):\n",
        "    final_dict.update({y:x+1})\n",
        "    idx_word.update({x+1:y})\n",
        "\n",
        "\n",
        "X = np.zeros((len(train_dict_new),len(value_item),  max_seq), dtype='int')\n",
        "Y = np.zeros((len(train_dict_new),len(value_item),  max_seq), dtype='int')\n",
        "\n",
        "images=[]\n",
        "X2=[]\n",
        "Y_train=[]\n",
        "\n",
        "for j,seqs in enumerate(train_dict_new.items()):\n",
        "    for   i, seq in enumerate(seqs[1]):\n",
        "        for t, word in enumerate(seq):\n",
        "            if t==0:\n",
        "                X[j,i,t]=final_dict[word]\n",
        "                continue\n",
        "            if word=='<stop>':\n",
        "                Y[j,i,t-1]=final_dict[word]\n",
        "                break\n",
        "            X[j,i,t]=final_dict[word]\n",
        "            Y[j,i,t-1]=final_dict[word]\n",
        "        X2.append(X[j,i,:])\n",
        "        Y_train.append(Y[j,i,:])\n",
        "        images.append(seqs[0])"
      ],
      "metadata": {
        "id": "RtYEqbTXzohF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[0,0,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvqGjhGRBTkg",
        "outputId": "398d2bba-7db5-4a18-eb49-79f42f33eea7"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  3,  8,  9, 10,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhi3mqOoBwO_",
        "outputId": "df1b34d5-ee3e-453a-ba39-83b63d17b67b"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 39)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract features from each photo in the directory\n",
        "def extract_features( image_keys):\n",
        "    # load the model\n",
        "    model = VGG16()\n",
        "    \n",
        "    # re-structure the model\n",
        "    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
        "    \n",
        "    # summarize\n",
        "    print(model.summary())\n",
        "    \n",
        "    # extract features from each photo\n",
        "    features ={}\n",
        "    \n",
        "    for seqs in image_keys:\n",
        "        \n",
        "        # load an image from file\n",
        "        filename = f'Flicker8k_Dataset/{seqs}'\n",
        "        \n",
        "        # load the image and convert it into target size of 224*224\n",
        "        image = load_img(filename, target_size=(224, 224))\n",
        "        \n",
        "        # convert the image pixels to a numpy array\n",
        "        image = img_to_array(image)\n",
        "        \n",
        "        # reshape data for the model\n",
        "        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "        \n",
        "        # prepare the image for the VGG model\n",
        "        image = preprocess_input(image)\n",
        "        \n",
        "        # get features\n",
        "        feature = model.predict(image, verbose=0)\n",
        "        \n",
        "        # get image id\n",
        "        \n",
        "        \n",
        "        # store feature\n",
        "        features.update({seqs:feature}) \n",
        "        \n",
        "#         print('>%s' % name)\n",
        "        \n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "Au44DiKvzpRE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_validate_features = extract_features(list(train_dict_new.keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGqX7i2u1Giu",
        "outputId": "b0644ccd-77dd-4aaa-c036-4ebbbee2d33c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 5s 0us/step\n",
            "553476096/553467096 [==============================] - 5s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,260,544\n",
            "Trainable params: 134,260,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X1=np.array(X1)"
      ],
      "metadata": {
        "id": "Cg0DN9vI7UDk"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1=[]\n",
        "for _,mtrix in enumerate(train_validate_features.items()):\n",
        "    X1.append(mtrix[1][0])"
      ],
      "metadata": {
        "id": "KQAjW7JK7rAl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1=[]\n",
        "for _,mtrix in enumerate(train_validate_features.items()):\n",
        "  for i in range (5):\n",
        "    # import pdb; pdb.set_trace()\n",
        "    X1.append(mtrix[1][0])"
      ],
      "metadata": {
        "id": "XJHur3tF_lv3"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMxqEtvP7aZc",
        "outputId": "1b74aa72-6e1e-4f14-9307-ddce6efdd34e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 4096)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X2=np.array(X2)"
      ],
      "metadata": {
        "id": "1pbNv75o72YT"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train=np.array(Y_train)"
      ],
      "metadata": {
        "id": "HOuVwa7i8VqT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs1= Input(shape=(4096,))\n",
        "fe1=Dropout(0.5)(inputs1)\n",
        "fe2=Dense(256,activation='relu')(fe1)\n",
        "\n",
        "inputs2= Input(shape=(max_seq))\n",
        "se1=Embedding(len(idx_word),256, mask_zero=True)(inputs2)\n",
        "se2=Dropout(0.5)(se1)\n",
        "se3=LSTM(256)(se2)\n",
        "\n",
        "decoder1=add([fe2,se3])\n",
        "decoder2=Dense(256,activation='relu')(decoder1)\n",
        "outputs=Dense(max_seq,activation='softmax')(decoder2)\n",
        "\n",
        "model=Model(inputs=[inputs1,inputs2], outputs=outputs)\n",
        "\n"
      ],
      "metadata": {
        "id": "2QmFOqB83rL8"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")"
      ],
      "metadata": {
        "id": "qlCgO5_B7A8H"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jtUd_dF_0ck",
        "outputId": "36ca6a24-f172-4246-c016-706efba83940"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 39)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir = \"/content/drive/MyDrive/Fina_Prj/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n"
      ],
      "metadata": {
        "id": "ozB42DM18Cho"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit([X1,X2],Y_train,batch_size=64,epochs=10,verbose=1,callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDOowmwJ7ELL",
        "outputId": "21d9e112-920d-4b05-c0ff-6d35d6df420a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 11s 11ms/step - loss: 253037792.0000 - accuracy: 0.1284\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 2080877952.0000 - accuracy: 0.1286\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 6883723264.0000 - accuracy: 0.1286\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 15800643584.0000 - accuracy: 0.1286\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 29765738496.0000 - accuracy: 0.1286\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 51017019392.0000 - accuracy: 0.1286\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 78888640512.0000 - accuracy: 0.1286\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 117351907328.0000 - accuracy: 0.1286\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 166493798400.0000 - accuracy: 0.1286\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 226175156224.0000 - accuracy: 0.1286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZP3nSL58L8e",
        "outputId": "b77a1c8a-f9af-4708-84bf-2b37f2c5648b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6000, 5, 39)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}